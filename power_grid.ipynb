{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ya3T9zDG082"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# SMART GRID STABILITY ANALYSIS PIPELINE\n",
        "# ===============================\n",
        "# Author: Research Workflow for Smart Grid Fault Detection (MLP-HF)\n",
        "# ===============================\n",
        "\n",
        "# --- IMPORT LIBRARIES ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             matthews_corrcoef, roc_curve, roc_auc_score, confusion_matrix)\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy import stats\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- LOAD DATASET ---\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset.csv\")\n",
        "\n",
        "# --- PREPROCESSING ---\n",
        "df = df.drop_duplicates().dropna()\n",
        "le = LabelEncoder()\n",
        "df['stabf'] = le.fit_transform(df['stabf'])  # 1 = unstable, 0 = stable\n",
        "\n",
        "X = df.drop(['stab', 'stabf'], axis=1)\n",
        "y = df['stabf']\n",
        "\n",
        "# Normalization and Standardization\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# --- FEATURE SELECTION METHODS ---\n",
        "\n",
        "## 1. PCA Feature Reduction\n",
        "pca = PCA(n_components=5)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "explained_var = np.cumsum(pca.explained_variance_ratio_)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(1, len(explained_var)+1), explained_var, marker='o', color='b')\n",
        "plt.title(\"Explained Variance (PCA)\", fontsize=14)\n",
        "plt.xlabel(\"Principal Components\")\n",
        "plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "## 2. Mutual Information\n",
        "mi = mutual_info_classif(X_scaled, y)\n",
        "mi_scores = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=mi_scores, y=mi_scores.index, palette=\"viridis\")\n",
        "plt.title(\"Feature Importance via Mutual Information\")\n",
        "plt.xlabel(\"Mutual Information Score\")\n",
        "plt.show()\n",
        "\n",
        "## 3. Correlation Matrix\n",
        "corr = X_scaled.corrwith(y)\n",
        "plt.figure(figsize=(8,5))\n",
        "corr.sort_values().plot(kind='barh', color='teal')\n",
        "plt.title(\"Feature Correlation with Target\")\n",
        "plt.show()\n",
        "\n",
        "## 4. KMeans Clustering with Silhouette Analysis\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "df['Cluster'] = clusters\n",
        "sil = silhouette_score(X_scaled, clusters)\n",
        "print(f\"Silhouette Score: {sil:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.heatmap(X_scaled.corr(), cmap='coolwarm', center=0)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Cluster', hue='stabf', data=df, palette='pastel')\n",
        "plt.title(\"Cluster Distribution by Stability\")\n",
        "plt.show()\n",
        "\n",
        "# --- SPLITTING ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# --- MODELLING ---\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "models = {\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"LR\": LogisticRegression(),\n",
        "    \"RF\": RandomForestClassifier(n_estimators=100),\n",
        "    \"XGB\": XGBClassifier(eval_metric='logloss')\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
        "    duration = time.time() - start\n",
        "    results.append([name, acc, prec, rec, f1, mcc, auc, duration])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\",\"Acc\",\"Prec\",\"Rec\",\"F1\",\"MCC\",\"AUC\",\"TrainTime(min)\"])\n",
        "results_df[\"TrainTime(min)\"] = results_df[\"TrainTime(min)\"]/60\n",
        "print(results_df)\n",
        "\n",
        "# --- ROC CURVES ---\n",
        "plt.figure(figsize=(8,6))\n",
        "for name, model in models.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc_score(y_test, model.predict_proba(X_test)[:,1]):.2f})\")\n",
        "plt.plot([0,1],[0,1],'--',color='gray')\n",
        "plt.legend()\n",
        "plt.title(\"ROC Curves for Models (All Features)\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.show()\n",
        "\n",
        "# --- SHAP ANALYSIS ---\n",
        "best_model = RandomForestClassifier().fit(X_train, y_train)\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values[1], X_test, plot_type=\"bar\")\n",
        "\n",
        "# --- LIME EXPLANATION ---\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=np.array(X_train),\n",
        "    feature_names=X.columns,\n",
        "    class_names=['Stable','Unstable'],\n",
        "    mode='classification'\n",
        ")\n",
        "exp = lime_explainer.explain_instance(X_test.iloc[5], best_model.predict_proba)\n",
        "exp.show_in_notebook(show_table=True)\n",
        "\n",
        "# --- STATISTICAL TESTING ---\n",
        "anova_p = stats.f_oneway(*[model.predict(X_test) for model in models.values()])[1]\n",
        "friedman_p = stats.friedmanchisquare(*[model.predict(X_test) for model in models.values()])[1]\n",
        "print(f\"ANOVA p-value: {anova_p:.4f}, Friedman p-value: {friedman_p:.4f}\")\n",
        "\n",
        "# --- FEATURE IMPORTANCE SUMMARY ---\n",
        "importances = pd.Series(best_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=importances, y=importances.index, palette=\"Set3\")\n",
        "plt.title(\"Feature Importance (Random Forest)\")\n",
        "plt.show()\n"
      ]
    }
  ]
}